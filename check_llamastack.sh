#!/bin/bash
# Script de v√©rification de llama-stack-instance

set -e

NAMESPACE="llama-serve"
DISTRIBUTION_NAME="llama-stack-instance"

echo "üîç V√©rification de llama-stack-instance"
echo "========================================"
echo ""

# 1. V√©rifier le LlamaStackDistribution
echo "1Ô∏è‚É£  √âtat du LlamaStackDistribution:"
oc get llamastackdistribution ${DISTRIBUTION_NAME} -n ${NAMESPACE} -o jsonpath='{.status.phase}' 2>/dev/null && echo "" || echo "‚ùå Non trouv√©"
echo ""

# 2. V√©rifier les conditions
echo "2Ô∏è‚É£  Conditions:"
oc get llamastackdistribution ${DISTRIBUTION_NAME} -n ${NAMESPACE} -o jsonpath='{range .status.conditions[*]}{.type}: {.status} ({.reason}){"\n"}{end}' 2>/dev/null || echo "Aucune condition trouv√©e"
echo ""

# 3. V√©rifier le service
echo "3Ô∏è‚É£  Service:"
if oc get svc llama-stack-instance-service -n ${NAMESPACE} &>/dev/null; then
    echo "‚úÖ Service existe"
    oc get svc llama-stack-instance-service -n ${NAMESPACE} -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}' && echo ""
else
    echo "‚ùå Service non trouv√©"
fi
echo ""

# 4. V√©rifier les endpoints
echo "4Ô∏è‚É£  Endpoints:"
ENDPOINTS=$(oc get endpoints llama-stack-instance-service -n ${NAMESPACE} -o jsonpath='{.subsets[0].addresses[*].ip}' 2>/dev/null)
if [ -n "$ENDPOINTS" ]; then
    echo "‚úÖ Endpoints: $ENDPOINTS"
else
    echo "‚ùå Aucun endpoint pr√™t"
    NOT_READY=$(oc get endpoints llama-stack-instance-service -n ${NAMESPACE} -o jsonpath='{.subsets[0].notReadyAddresses[*].ip}' 2>/dev/null)
    if [ -n "$NOT_READY" ]; then
        echo "‚ö†Ô∏è  Endpoints non pr√™ts: $NOT_READY"
    fi
fi
echo ""

# 5. V√©rifier les pods
echo "5Ô∏è‚É£  Pods:"
PODS=$(oc get pods -n ${NAMESPACE} -l app.kubernetes.io/name=${DISTRIBUTION_NAME} -o jsonpath='{.items[*].metadata.name}' 2>/dev/null)
if [ -n "$PODS" ]; then
    for pod in $PODS; do
        PHASE=$(oc get pod $pod -n ${NAMESPACE} -o jsonpath='{.status.phase}' 2>/dev/null)
        echo "   Pod: $pod - Phase: $PHASE"
        if [ "$PHASE" != "Running" ]; then
            echo "   ‚ö†Ô∏è  Pod non en cours d'ex√©cution"
            oc get pod $pod -n ${NAMESPACE} -o jsonpath='{.status.containerStatuses[*].state.waiting.reason}' 2>/dev/null | grep -q . && \
                oc get pod $pod -n ${NAMESPACE} -o jsonpath='{.status.containerStatuses[*].state.waiting.reason}' && echo ""
        fi
    done
else
    echo "‚ùå Aucun pod trouv√©"
fi
echo ""

# 6. V√©rifier la configuration VLLM_URL
echo "6Ô∏è‚É£  Configuration VLLM_URL:"
VLLM_URL=$(oc get llamastackdistribution ${DISTRIBUTION_NAME} -n ${NAMESPACE} -o jsonpath='{.spec.server.containerSpec.env[?(@.name=="VLLM_URL")].value}' 2>/dev/null)
if [ -n "$VLLM_URL" ]; then
    echo "   VLLM_URL: $VLLM_URL"
    # Extraire le nom du service
    SERVICE_NAME=$(echo $VLLM_URL | sed 's|http://||' | sed 's|:.*||')
    NAMESPACE_VLLM=$(echo $SERVICE_NAME | cut -d'.' -f2)
    echo "   Service attendu: $SERVICE_NAME dans namespace: $NAMESPACE_VLLM"
    
    # V√©rifier si le service existe
    if oc get svc $(echo $SERVICE_NAME | cut -d'.' -f1) -n ${NAMESPACE_VLLM:-llama-serve} &>/dev/null; then
        echo "   ‚úÖ Service vLLM trouv√©"
    else
        echo "   ‚ùå Service vLLM non trouv√©: $(echo $SERVICE_NAME | cut -d'.' -f1)"
    fi
else
    echo "   ‚ö†Ô∏è  VLLM_URL non configur√©"
fi
echo ""

# 7. V√©rifier le mod√®le INFERENCE_MODEL
echo "7Ô∏è‚É£  Configuration INFERENCE_MODEL:"
INFERENCE_MODEL=$(oc get llamastackdistribution ${DISTRIBUTION_NAME} -n ${NAMESPACE} -o jsonpath='{.spec.server.containerSpec.env[?(@.name=="INFERENCE_MODEL")].value}' 2>/dev/null)
echo "   INFERENCE_MODEL: ${INFERENCE_MODEL:-non configur√©}"
echo ""

# 8. R√©sum√©
echo "üìä R√âSUM√â"
echo "========="
PHASE=$(oc get llamastackdistribution ${DISTRIBUTION_NAME} -n ${NAMESPACE} -o jsonpath='{.status.phase}' 2>/dev/null)
echo "Phase: $PHASE"

DEPLOYMENT_READY=$(oc get llamastackdistribution ${DISTRIBUTION_NAME} -n ${NAMESPACE} -o jsonpath='{.status.conditions[?(@.type=="DeploymentReady")].status}' 2>/dev/null)
echo "Deployment Ready: $DEPLOYMENT_READY"

SERVICE_READY=$(oc get llamastackdistribution ${DISTRIBUTION_NAME} -n ${NAMESPACE} -o jsonpath='{.status.conditions[?(@.type=="ServiceReady")].status}' 2>/dev/null)
echo "Service Ready: $SERVICE_READY"

HEALTH_CHECK=$(oc get llamastackdistribution ${DISTRIBUTION_NAME} -n ${NAMESPACE} -o jsonpath='{.status.conditions[?(@.type=="HealthCheck")].status}' 2>/dev/null)
echo "Health Check: $HEALTH_CHECK"
echo ""

if [ "$DEPLOYMENT_READY" != "True" ] || [ "$HEALTH_CHECK" != "True" ]; then
    echo "‚ùå llama-stack-instance ne fonctionne PAS correctement"
    echo ""
    echo "üí° Solutions:"
    echo "   1. V√©rifier que le mod√®le vLLM attendu est d√©ploy√©"
    echo "   2. V√©rifier les logs: oc logs -n ${NAMESPACE} -l app.kubernetes.io/name=${DISTRIBUTION_NAME}"
    echo "   3. Utiliser directement votre mod√®le: llama-instruct-32-3b"
    exit 1
else
    echo "‚úÖ llama-stack-instance fonctionne correctement"
    exit 0
fi

